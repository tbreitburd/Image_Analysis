\documentclass[12pt]{report} % Increased the font size to 12pt
\usepackage{epigraph}
\usepackage{geometry}

% Optional: customize the style of epigraphs
\setlength{\epigraphwidth}{0.5\textwidth} % Adjust the width of the epigraph
\renewcommand{\epigraphflush}{flushright} % Align the epigraph to the right
\renewcommand{\epigraphrule}{0pt} % No horizontal rule
\usepackage[most]{tcolorbox}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[utf8]{inputenc}
\usepackage{hyperref} % Added for hyperlinks
\usepackage{listings} % Added for code listings
\usepackage{color}    % Added for color definitions
\usepackage[super]{nth}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{cite}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{cleveref}
\usetikzlibrary{shapes.geometric, arrows, positioning}

\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=red!30]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

% Define the graphics path
%\graphicspath{{./Plots/}}

% Define the header and footer for general pages
\pagestyle{fancy}
\fancyhf{} % Clear all header and footer fields
\fancyhead{} % Initially, the header is empty
\fancyfoot[C]{\thepage} % Page number at the center of the footer
\renewcommand{\headrulewidth}{0pt} % No header line on the first page of chapters
\renewcommand{\footrulewidth}{0pt} % No footer line

% Define the plain page style for chapter starting pages
\fancypagestyle{plain}{%
  \fancyhf{} % Clear all header and footer fields
  \fancyfoot[C]{\thepage} % Page number at the center of the footer
  \renewcommand{\headrulewidth}{0pt} % No header line
}

% Apply the 'fancy' style to subsequent pages in a chapter
\renewcommand{\chaptermark}[1]{%
  \markboth{\MakeUppercase{#1}}{}%
}

% Redefine the 'plain' style for the first page of chapters
\fancypagestyle{plain}{%
  \fancyhf{}%
  \fancyfoot[C]{\thepage}%
  \renewcommand{\headrulewidth}{0pt}%
}

% Header settings for normal pages (not the first page of a chapter)
\fancyhead[L]{\slshape \nouppercase{\leftmark}} % Chapter title in the header
\renewcommand{\headrulewidth}{0.4pt} % Header line width on normal pages

\setlength{\headheight}{14.49998pt}
\addtolength{\topmargin}{-2.49998pt}
% Define colors for code listings
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Setup for code listings
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

% Definition of the tcolorbox for definitions
\newtcolorbox{definitionbox}[1]{
  colback=red!5!white,
  colframe=red!75!black,
  colbacktitle=red!85!black,
  title=#1,
  fonttitle=\bfseries,
  enhanced,
}

% Definition of the tcolorbox for remarks
\newtcolorbox{remarkbox}{
  colback=blue!5!white,     % Light blue background
  colframe=blue!75!black,   % Darker blue frame
  colbacktitle=blue!85!black, % Even darker blue for the title background
  title=Remark:,            % Title text for remark box
  fonttitle=\bfseries,      % Bold title font
  enhanced,
}

% Definition of the tcolorbox for examples
\newtcolorbox{examplebox}{
  colback=green!5!white,
  colframe=green!75!black,
  colbacktitle=green!85!black,
  title=Example:,
  fonttitle=\bfseries,
  enhanced,
}

% Definitions and examples will be put in these environments
\newenvironment{definition}
    {\begin{definitionbox}}
    {\end{definitionbox}}

\newenvironment{example}
    {\begin{examplebox}}
    {\end{examplebox}}

\geometry{top=1.5in} % Adjust the value as needed
% ----------------------------------------------------------------------------------------


\title{Image Analysis Coursework Report}
\author{CRSiD: tmb76}
\date{University of Cambridge}

\begin{document}

\maketitle

\tableofcontents

\chapter*{}

\chapter{Fundamentals of Image Analysis}

\section{Exercise 1.1}

In this exercise, 3 images were used to test different segmetentation methods. For each image, a specific segmentation objective was set, and 3 differemt main algorithms were used to segment the images, along with some additional methods.

\subsection{Image 1: \texttt{CT.png}}

The first image, \texttt{CT.png}, is a CT scan of a human torso. The objective of this segmentation is to segment the lungs from the rest of the image, including any tissue or nodule inside it. This segmentation was done using a region-growing algorithm. Region-growing (or the \texttt{skimage.segmentation.flood\_fill} function) is a conceptually simple algorithm. Starting from a seed-pixel with a certain value, the algorithm grows the region by adding neighbouring pixels that are within a certain threshold of the current region. This is done iteratively until the region stops growing\cite{skimage_flood_fill}\cite[pp.764-766]{gonzalez2002digital}.

The first part of the segmentation was to divide the image into regions, from which it was then possible to set seeds for the region-growing algorithm inside each lung. Getting the regions was done using thresholding and closing. Thresholding is a simple image processing method where by setting a threshold value, one creates a binary image where all pixels above the threshold are set to 1 (0 otherwise)\cite[p.743]{gonzalez2002digital}. Setting the threshold value is done by selecting the value which maximises the between-class variance of the resulting binary image\cite[pp. 747-751]{gonzalez2002digital}. Closing is a morphological operation that is used to fill in small holes (locations with value 0) in the binary image. The first step is to dilate the image then erode it\cite[pp.645-648]{gonzalez2002digital}. Erosion and dilation are two morphological operation that can be considered as filtering operation. The former filters image details smallet than the structuring element, which is a small template set of pixels used to filter the image\cite[pp. 636-638]{gonzalez2002digital}. The latter filters images in a similar way, but by switching what is considered the background of the image and what is cosnidered an object. Here, this means that erosion will remove small 1-valued regions, while dilation will remove small 0-valued regions.

Once this is done, regions are identified. This is done by taking each continuous area of a single value in the binary image, and assigning it a unique label\cite{skimage_measure_label}. From there, the lungs were identified as the 2 smallest regions. The seeds for the region-growing algorithm were then set as the middle point in that region (not centroid, but middle of the array). The region-growing algorithm is then used, obtaining segmentations of the lungs. Thresholding and closing where then again used to get smooth and continuous segmentations. This entire process is shown in Figure \ref{fig:ct_segmentation}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/CT_Segmentation.png}
    \caption{The segmentation of the \texttt{CT.png} image.}
    \label{fig:ct_segmentation}
\end{figure}

\subsection{Image 2: \texttt{noisy\_flower.jpg}}

Here, the task was to segment purple tulips from an image of a Dutch tulip field. The main challenge here was the presence of noise in the image, resulting in the purple tulips not being a uniform colour, and other tulips containing some purple. Since the main information here is the color and not so much the brightness of the image, the segmentation was done in the HSV color space. This is a color space that encodes images as hue (color), saturation (intensity of that color), and value (brightness) making it easier to segment based on color\cite{wiki_hsv}. Plotting grayscale images of each of those channels (see Figure \ref{fig:flower_hsv}), it can be seen that the hue channel is most useful for segmentation.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/tulip_hsv.png}
    \caption{The HSV channels of the \texttt{noisy\_flower.jpg} image.}
    \label{fig:flower_hsv}
\end{figure}

It can also be seen that, conveniently, the purple hue is close to the largest value on the spectrum, with the exception of red which is at both extremities. And looking at the histogram of the hue channel, with hue overlaid, one can see that using a single threshold may already be very helpful in segmenting the image (see \ref{fig:hsv_hist}). Applyin that threshold, the resulting image will be a noisy binary image. But by applying opening (erosion then dilation, see Sec. 1.1.1.) to the image, this removes the darker noise in lighter regions. A gaussian filter is then applied\cite[pp. 166-170]{gonzalez2002digital}, smoothing out the binary image's noise, and giving back a grayscale image.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/tulip_hue_hist.png}
    \caption{The histogram of the hue channel of the \texttt{noisy\_flower.jpg} image.}
    \label{fig:hsv_hist}
\end{figure}

Finally, the main algorithm used for this image is the Chan-Vese segmentation algorithm\cite{chan1999active}. This algorithm performs well for objects without clear boundaries. It works by iteratively updating a level set to minimize an energy/loss function, defined as the sum of intensity difference from the average values inside and outside segmented regions\cite{skimage_chan_vese}. Finally, opening is applied to the segmented image to remove small regions segmented by Chan-Vese from the noise, which do not correspond to the purple tulips. The result of this complete process is shown in Figure \ref{fig:tulip_segmentation}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/tulip_segmentation.png}
    \caption{The segmentation process of the \texttt{noisy\_flower.jpg} image.}
    \label{fig:tulip_segmentation}
\end{figure}

\subsection{Image 3: \texttt{coins.png}}

For this problem, the task was to segment specific coins from an image of antique coins, which has been corrupted with vertical black lines across the image. Specifically, the 1st coin of the 1st row, 2nd coin of the 2nd row, and so on until the 4th row. Here, the main challenge was dealing with the lines and then the lighter background at the top left of the image, which almost matched the lighter shade of the coin.

The segmentation for this problem first made use of an inpainting algorithm \cite{skimage_inpaint_biharmonic}. This uses biharmonic functions, constructed using Lpalacinan and normal derivatives of the boundary data\cite{damelin2018surface}. Once the image is inpainted, the contrast of the image is increased using the scikit-image \texttt{exposure.rescale\_intensity} function. This function linearly scales the intensity of the image to a certain range, which can be set as the minimum and maximum values of the image\cite{skimage_rescale_intensity}. This is done to make the coins more distinguishable from the background.

The second part of the segmentation was to try and remove the background of the image, using a rolling-ball algorithm. This is akin to a filter as it uses kernels to define the shape of the object that is "rolled". For a sphere kernel, one can imagine creating a discretized surface where each square column represents a pixel, and having a ball roll on the underside of that surface. With sufficient radius, that sphere will not "fall up" in the peaks of the image, and the background will be estimated as the height of the apex of the ball\cite{skimage_rolling_ball}. With the background estimates, it can be subtracted from the image, making the segmentation of the coins easier.

Third, K-means clustering is used to segment all the coins in the image. By setting the number of clusters to 2, the algorithm initializes two values between 0 and 255. It then assigns each pixel to the cluster with the closest mean value. This process is repeated iteratively until the cluster assignments no longer change, resulting in the image being divided into two regions\cite{sklearn_kmeans}. The coins are then labelled, and the chosen coins are isolated from those labels. The result of this process is shown for each coin in Figures \ref{fig:coin_7_segmentation}, \ref{fig:coin_16_segmentation}, \ref{fig:coin_23_segmentation}, and \ref{fig:coin_27_segmentation}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/Coin_segmentation_7.png}
    \caption{The segmentation of the 1st coin in the 1st row.}
    \label{fig:coin_7_segmentation}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/Coin_segmentation_16.png}
    \caption{The segmentation of the 2nd coin in the 2nd row.}
    \label{fig:coin_16_segmentation}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/Coin_segmentation_23.png}
    \caption{The segmentation of the 3rd coin in the 3rd row.}
    \label{fig:coin_23_segmentation}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../Plots/Coin_segmentation_27.png}
    \caption{The segmentation of the 4th coin in the 4th row.}
    \label{fig:coin_27_segmentation}
\end{figure}


\chapter{Inverse Problems and Multiresolution Analysis}

\section{Exercise 2.1}

In this exercise, the solving of ill-posed inverse problems is done for a simple 1D example of fitting a straight line to noisy data. This will be done using a minimisation algorithm of the form:

\begin{equation}
    \min_{u} ||Au - f||_{l_{n}}
\end{equation}

Where A is the parameter matrix, u is the measured input, and $l_{n}$ describes the type of distance used to measure the error between the model and the data. Here, A is the vector $[a, b]$, where $a$ is the slope and $b$ is the intercept of the fitted line. And the two choices considered are $l_{1}$ and $l_{2}$ minimisation.

\subsection{\texorpdfstring{$l_{1}$ and $l_{2}$ Minimisation}{l1 and l2 Minimisation}}

As defined, $l_{1}$ minimisation is the minimisation of the sum of the absolute values of the residuals\cite{wiki_lad}, while $l_{2}$ minimisation is the minimisation of the sum of the squares of the residuals\cite{margalit2021method}. Switching to a more explicit notation of this problem, this gives:

\begin{equation}
    ||(ax + b) - f||_{l_{1}} = \sum_{i=1}^{n} |(ax_{i} + b) - f_{i}|
\end{equation}

\begin{equation}
    ||(ax + b) - f||_{l_{2}} = \sqrt{\sum_{i=1}^{n} ((ax_{i} + b) - f_{i})^{2}}
\end{equation}

The $l_{1}$ minimisation problem is quite uncommon due to it not being differentiable, and resulting in the problem not having an analytical solution.

In this problem, some noisy data was obtained from two files, \texttt{y\_line.txt} and \texttt{y\_outlier\_line.txt}, where the latter has the same data but with one outlier. The data was then fitted with a straight line using the two minimisation methods. For $l_{1}$, the \texttt{scipy.optimise.minimise} function was used using the Sequential Least Squares Programming (SLSQP) method. This is a way to solve the minimizing problem using linear programming, by replacing the original problem with a series of quadratic problems that are easier to solve\cite{mathse_slsqp}. Using this method, the fitted parameters were otbtained and are shown in Table \ref{tab:l1_fits}, and the plots of the fitted lines are shown in Figure \ref{fig:l1_fits}.

\begin{table}
    \begin{center}
        \begin{tabular}{ccc}
            \hline
            & \textbf{Slope} & \textbf{Intercept} \\
            \hline
            \textbf{Noisy Data} & 0.0663 & 0.3092 \\
            \textbf{Data w/ Outliers} & 0.0662 & 0.3120 \\
            \hline
        \end{tabular}
        \caption{Table of the fitted parameters for the straight line using $l_{1}$ minimisation.}
        \label{tab:l1_fits}
    \end{center}
\end{table}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{../Plots/l1_noisy_data.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{../Plots/l1_outlier_data.png}
    \end{subfigure}
    \caption{Plots of the fitted straight line to the noisy (left), and outlier (right) data using $l_{1}$ minimisation, assuming the x-coordinate of the data points is the index of the data point.}
    \label{fig:l1_fits}
\end{figure}

For $l_{2}$ minimisation, the \texttt{scikit-learn} library was used to fit the data using the \texttt{LinearRegression} class, which uses the Ordinary Least Squares method to fit the data\cite{sklearn_linear_regression}. The fitted parameters were obtained and are shown in Table \ref{tab:l2_fits}, and the plots of the fitted lines are shown in Figure \ref{fig:l2_fits}.

\begin{table}
    \begin{center}
        \begin{tabular}{ccc}
            \hline
            & \textbf{Slope} & \textbf{Intercept} \\
            \hline
            \textbf{Noisy Data} & 0.0665 & 0.2838 \\
            \textbf{Data w/ Outliers} & 0.0462 & 0.6266 \\
            \hline
        \end{tabular}
        \caption{Table of the fitted parameters for the straight line using $l_{2}$ minimisation.}
        \label{tab:l2_fits}
    \end{center}
\end{table}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{../Plots/l2_noisy_data.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{../Plots/l2_outlier_data.png}
    \end{subfigure}
    \caption{Plots of the fitted straight line to the noisy (left), and outlier (right) data using $l_{2}$ minimisation, assuming the x-coordinate of the data points is the index of the data point.}
    \label{fig:l2_fits}
\end{figure}

\subsection{Discussion}

It is clear that $l_{1}$ minimisation is more robust to outliers than $l_{2}$ minimisation, as the $l_{1}$ fitted line for the data with outliers is almost identical to the line fitted to the noisy data. Whereas the $l_{2}$ fitted line for the data with outliers differs significantly from the line fitted to the noisy data. This can be explained from the definition of the two minimisation methods, where due to the squaring of the difference in $l_{2}$ minimisation, the effect of outliers on the objective function ($||(ax + b) - f||_{l_{2}}$) is amplified.

\section{Exercise 2.2}

In this exercise, the importance of random undersampling in compressed sensing theory. In order to do this, random and uniform undersampling will be compared in the reconstruction of a noisy signal, by solving:

\begin{equation}
    \text{arg} \min{(\frac{1}{2}||\mathcal{F}_{\Omega}\hat{x} - y||^{2}_{2} + \lambda |\hat{x}|_{1})}
\end{equation}


Using an iterative soft thresholding algorithm, with a data consistency constraint:

\begin{equation}
    \hat{f}_{i+1}[j] =
    \begin{cases}
        \hat{f}_{i}[j] & \text{if } y[j] = 0 \\
        y[j] & \text{otherwise}
    \end{cases}
\end{equation}

\subsection{Getting undersampled signals}

First, a noisy signal is created. This is done by first creating a zero-filled vector of length 100 and replacing 10 entries by non-zero coefficients between 0 and 1. Gaussian noise, with mean 0 and standard deviation 0.05 is then added to all entries. This results in a noisy vector shown in Figure\ref{fig:noisy_signal}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.2_signal_vector.png}
    \caption{Plot of the noisy signal.}
    \label{fig:noisy_signal}
\end{figure}

The signal is then undersampled using two methods: random and uniform. For random undersampling, 32 entries from the vector are sampled randomly (without repeats). For uniform undersampling, \texttt{numpy.linspace} was used to get 32 regularly spaced samples from the noisy signal. The inverse Fourier Transform of the undersampled signal is computed and then multiplied by 4. The resulting "measured" undersampled signals are shown in Figure \ref{fig:undersampled_signals}.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{../Plots/q2.2_random_signal.png}
        \caption{Random Undersampling}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{../Plots/q2.2_uniform_signal.png}
        \caption{Uniform Undersampling}
    \end{subfigure}
    \caption{Plots of the undersampled signals.}
    \label{fig:undersampled_signals}
\end{figure}

With the undersampled signals the goal is now to reconstruct the original signal


\subsection{The Iterative Soft Thresholding Algorithm}

In order to reconstruct the original signal, the iterative soft thresholding algorithm is used. This algorithm is an iterative method that solves the  minimisation problem descirbed above by iteratively applying a soft thresholding function to the signal. The algorithm is as follows:

\begin{definitionbox}{Algorithm 1: Iterative Soft Thresholding Algorithm}
    \begin{algorithmic}[1]

        \State $\hat{X}_{0} \gets y$ \Comment{Initial guess}
        \For{$i \leq N_{iter}$} \Comment{Iterate $i = 0, 1, \dots, N_{iter}$}
            \State $\hat{x}_{i} \gets \mathcal{F}^{-1}\hat{X}_{i}$ \Comment{Get an estimate of the signal}
            \State $\hat{x}_{i} \gets \text{SoftThresh}(\hat{x}_{i}, \lambda)$ \Comment{Apply Soft Thresholding}
            \State $\hat{X}_{i} \gets \mathcal{F}\hat{x}_{i}$ \Comment{Compute Fourier Transform}
            \If{$y[j] = 0$} \Comment{Data Consistency Constraint}
                \State $\hat{X}_{i+1}[j] \gets \hat{X}_{i}[j]$
            \Else
                \State $\hat{X}_{i+1}[j] \gets y[j]$
            \EndIf
            \State $i \gets i + 1$
        \EndFor
        \end{algorithmic}
    This could also be set up as a while loop, where the algorithm stops when the difference between the current and previous estimate is below a certain threshold, i.e. when it converges
\end{definitionbox}



\subsection{Discussion}

\section{Exercise 2.3}

In this exercise, compressed reconstruction is discussed, specifically how images can have sparse representations in the wavelet transform domain. In this case, the wavelet transform used is the Daubechies wavelet transform, and the image is then reconstructed. The process of thresholding the wavelet coefficients is also discussed. In Figure \ref{fig:riverside}, the image studied is shown.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside.png}
    \caption{The riverside image studied in this exercise.}
    \label{fig:riverside}
\end{figure}

\subsection{Daubechies Wavelet Transform}

Discrete wavelet transforms make the use of a scaling function adn wavelets to express images as a linear combination of them. The scaling function generates a series of approximations of the image, and the wavelets encode the differences between adjacent approximations. And the decomposition can be made at different resolution levels, with each level encoding more detail of the image\cite{mallat1989theory}.

Once computed, the wavelet coefficients can be visualised as an image, as shown in Figures \ref{fig:wavelet_coefficients} and \ref{fig:wavelet_coefficients2}. As can be seen, each describes details of the image at different scales. Namely, the 2nd level coefficients seem to capture the features of the riverside image more intensely than the 1st level coefficients.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{../Plots/q2.3_daubechies_lvl1.png}
    \caption{The 1st scaling level Daubechies wavelet transform coefficients of the riverside image.}
    \label{fig:wavelet_coefficients}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{../Plots/q2.3_daubechies_lvl2.png}
    \caption{The 2nd scaling level Daubechies wavelet transform coefficients of the riverside image.}
    \label{fig:wavelet_coefficients2}
\end{figure}

One can then reconstruct it using the inverse wavelet transform, and the image is shown in Figure \ref{fig:reconstructed_image}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{../Plots/q2.3_riverside_reconstructed.png}
    \caption{The reconstructed riverside image using the Daubechies wavelet transform.}
    \label{fig:reconstructed_image}
\end{figure}

And comparing this with the original image (\ref{fig:diff_image}), it can be seen that the reconstruction is quite good, with the main features of the image being preserved. However, one can also see that there is a significant amount of noise in the reconstruction, or indeed in the original image. This is where thresholding comes in.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_diff.png}
    \caption{The difference between the original and reconstructed riverside images.}
    \label{fig:diff_image}
\end{figure}

\subsection{Thresholding Coefficients}

For the second part of this exercise, the task was to threshold the wavelet coefficients, keeping only the largest $P$\% of the coefficients. This is done using the \texttt{pywt.threshold} function from the \texttt{pywavelets} library. The thresholding is done using the hard thresholding method, which is simply defined as:

\begin{equation}
    \text{HardThresh}(x, \lambda) =
    \begin{cases}
        x & \text{if } |x| > \lambda \\
        0 & \text{otherwise}
    \end{cases}
\end{equation}

Thus, this method is used for the top 2.5, 5, 10, 15, and 20\% of the coefficients. The result for the top 15\% threshold is shown in figures \ref{fig:thresholded_image15} and \ref{fig:thresholded_image15_2}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_15.png}
    \caption{The thresholded riverside image 1st level Daubechies wavelet transform coefficients, for a top 15\% threshold.}
    \label{fig:thresholded_image15}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_15_2.png}
    \caption{The thresholded riverside image 2nd level Daubechies wavelet transform coefficients, for a top 15\% threshold.}
    \label{fig:thresholded_image15_2}
\end{figure}

For the other thresholds, the results are shown in Figures \ref{fig:thresholded_image20}, \ref{fig:thresholded_image20_2}, \ref{fig:thresholded_image10}, \ref{fig:thresholded_image10_2}, \ref{fig:thresholded_image5}, \ref{fig:thresholded_image5_2}, \ref{fig:thresholded_image2.5}, and \ref{fig:thresholded_image2.5_2}, in the Appendix. For each of these thresholds, the riverside image was reconstructed and compared to the original image. Again, this is first done for the 15\% threshold, and the results are shown in Figures \ref{fig:reconstructed_image15}, \ref{fig:diff_image15}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_reconstructed_15.png}
    \caption{The reconstructed riverside image using the thresholded Daubechies wavelet transform coefficients, for a top 15\% threshold.}
    \label{fig:reconstructed_image15}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_diff_15.png}
    \caption{The difference between the original and reconstructed riverside images, for a top 15\% threshold.}
    \label{fig:diff_image15}
\end{figure}


For the other thresholds, the results are shown in Figure \ref{fig:reconstructed_image20}, \ref{fig:reconstructed_image10},  \ref{fig:reconstructed_image5}, and \ref{fig:reconstructed_image2.5}, in the Appendix. And the differences between the original and reconstructed images are shown in Figure \ref{fig:diff_image20}, \ref{fig:diff_image10}, \ref{fig:diff_image5}, and \ref{fig:diff_image2.5}.


\subsection{Discussion}

As expected, the higher the threshold the less coefficient's information is kept, and for the 1st level decomposition, this reduces to a nearly blank image for thresholds lower than 15\%. However, reconstructions stays qualitatively good, and the difference plots show less noise in the reconstructed images the lower the threshold value. This is because the noise can be captured and will be seen in the lower value coefficients, and by thresholding these out, the "noise information" is lost. However, the thresholding also removes some of the detail in the image, as can be seen in the reconstructed images. This is a trade-off that must be considered when thresholding wavelet coefficients.

\chapter{Solving Inverse Problems}

In this chapter, the reconstruction of images from noisy data is discussed. And multiple methods are compared, mainly a classical model-driven regularization (Total Variation regularized reconstruction), and a data-driven regularization (Learned gradient descent with a neural network). The image studied is the Shepp-Logan phantom.

\section{Exercise 3.1}

As an entry problem into inverse problems, the task of minimizing the function \(f: \mathbb{R}^2 \to \mathbb{R}\) defined as

\begin{equation}
f(x) = \frac{1}{2} [x]_1^2 + [x]_2^2, \quad \text{where} \quad x = \begin{bmatrix} [x]_1 \\ [x]_2 \end{bmatrix},
\end{equation}

is considered. As gradient descent is the chosen method here, the gradient of the function must be computed and is given by: $\nabla f(x) = \begin{bmatrix} [x]_1 \\ 2[x]_2 \end{bmatrix}$. In order to use the $L$-smooth function property given in the coursework paper, it must be shown that the gradient of $f(x)$ is $L$-Lipschitz continuous. This is done by showing that for all $x, y \in \mathbb{R}^2$, there exists a constant $L$ such that \cite{lecture3}:

\begin{equation}
    ||\nabla f(x) - \nabla f(y)|| \leq L||x - y||
\end{equation}

This can be done by computing both norms, of the gradient differences and the vector differences. The norm of the gradient difference is given by:

\begin{equation}
    ||\nabla f(x) - \nabla f(y)|| = \left|\left| \begin{bmatrix} [x]_1 - [y]_1 \\ 2[x]_2 - 2[y]_2 \end{bmatrix} \right|\right| = \sqrt{([x]_1 - [y]_1)^2 + 4([x]_2 - [y]_2)^2}
\end{equation}

Then, for the vector difference norm:

\begin{equation}
    ||x - y|| = \left|\left| \begin{bmatrix} [x]_1 - [y]_1 \\ [x]_2 - [y]_2 \end{bmatrix} \right|\right| = \sqrt{([x]_1 - [y]_1)^2 + ([x]_2 - [y]_2)^2}
\end{equation}

And it is clear that the gradient of $f(x)$ is 2-Lipschitz continuous, as one can easily show that:

\begin{equation}
    \sqrt{([x]_1 - [y]_1)^2 + 4([x]_2 - [y]_2)^2} \leq 2 \times \sqrt{([x]_1 - [y]_1)^2 + ([x]_2 - [y]_2)^2}
\end{equation}

since the squared terms are positive so multiplying both of them by 4 will result in a larger value than just multiplying one. More formally, the smallest L that satisfies this condition is given by the maximum eigenvalue of the hessian matrix of $f(x)$\cite[claim 5]{lecture12}:

\begin{equation}
    \nabla^2 f(x) = \begin{bmatrix} 1 & 0 \\ 0 & 2 \end{bmatrix}
\end{equation}

And the eigenvalues of this matrix satisfy: $\text{det}(\lambda I - \nabla^2 f(x)) = 0$, which gives $(\lambda - 1)(\lambda - 2) = 0$, giving a maximum eigenvalue of 2. Thus, the gradient of $f(x)$ is $L$-Smooth with $L = 2$.

Thus, the following inequality holds:

\begin{equation}
    f(x_K) - f(x^*) \leq \frac{2 \|x_0 - x^*\|^2}{2K}
\end{equation}

where $x^*$ is the vector $X$ for which $f(x)$ is minimised, $x_0$ is the initial guess, and $x_K$ is the K-th iteration of the gradient descent algorithm. This inequality can be used to determine the number of iterations needed to reach a certain accuracy, given the initial guess and optimal vector. Now the function $f(x)$ has a clear minimum at $x^* = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$, and the gradient descent algorithm is run with an initial guess of $x_0 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$.

For that case, the value of K needed for the RHS of the inequality to be less than $\epsilon = 0.01$ is given by:

\begin{equation}
    0.01 \geq \frac{2 \|x_0 - x^*\|^2}{2K} \iff K \geq \frac{2 \|x_0 - x^*\|^2}{2\times 0.02} = \frac{2 \times 2}{0.02} = 200
\end{equation}

However, when applying the gradient descent algorithm, setting the learning rate to 1/L, the algorithm converges to an $\epsilon \leq 0.01$ in 3 iterations, and the evolution of the vector $x$'s components is shown in Figure \ref{fig:gradient_descent}. And the final value of $\epsilon$ is 0.0078.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q3_1_Convergence.png}
    \caption{The convergence of the gradient descent algorithm for the function $f(x)$.}
    \label{fig:gradient_descent}
\end{figure}



\section{Exercise 3.2}

In this exercise the 2 methods mentionned at the start of this chapter are compared. The first method implements the ADMM algorithm\cite{boyd2011distributed} to solve a Total Variation regularized reconstruction problem for the Shepp-Logan phantom image. The TV-regularized reconstruction problem is given by:

\begin{equation}
    \min_{u} ||y - Ax||^2_2 + \lambda ||\nabla x||_1
\end{equation}

where $y$ is the noisy sinogram of the image to be reconstructed, $A$ is the measurement matrix, $x$ is the image to be reconstructed, $\lambda$ is the regularization parameter, and $\nabla x$ is the gradient of the image. The ADMM algorithm is used to solve this problem, and the results are shown in Figure \ref{fig:tv_reconstruction}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q3.2_grd_truth_FBP.png}
    \caption{The TV-regularized reconstruction of the Shepp-Logan phantom image.}
    \label{fig:tv_reconstruction}
\end{figure}

The second method uses a neural network to solve the same problem, but with a learned gradient descent algorithm. The network is trained on the Shepp-Logan phantom image, and the results are shown in Figure \ref{fig:learned_reconstruction}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q3.2_grd_truth_FBP_ADMM_LGD.png}
    \caption{The learned gradient descent reconstruction of the Shepp-Logan phantom image.}
    \label{fig:learned_reconstruction}
\end{figure}

\chapter{Appendix}

\section{README}

\subsection{Extra Plots}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_20.png}
    \caption{The thresholded riverside image 1st level Daubechies wavelet transform coefficients, for a top 20\% threshold.}
    \label{fig:thresholded_image20}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_20_2.png}
    \caption{The thresholded riverside image 2nd level Daubechies wavelet transform coefficients, for a top 20\% threshold.}
    \label{fig:thresholded_image20_2}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_10.png}
    \caption{The thresholded riverside image 1st Daubechies wavelet transform coefficients, for a top 10\% threshold.}
    \label{fig:thresholded_image10}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_10_2.png}
    \caption{The thresholded riverside image 2nd Daubechies wavelet transform coefficients, for a top 10\% threshold.}
    \label{fig:thresholded_image10_2}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_5.png}
    \caption{The thresholded riverside image 1st level Daubechies wavelet transform coefficients, for a top 5\% threshold.}
    \label{fig:thresholded_image5}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_5_2.png}
    \caption{The thresholded riverside image 2nd level Daubechies wavelet transform coefficients, for a top 5\% threshold.}
    \label{fig:thresholded_image5_2}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_2_5.png}
    \caption{The thresholded riverside image 1st level Daubechies wavelet transform coefficients, for a top 2.5\% threshold.}
    \label{fig:thresholded_image2.5}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_daubechies_thresh_2_5_2.png}
    \caption{The thresholded riverside image 2nd level Daubechies wavelet transform coefficients, for a top 2.5\% threshold.}
    \label{fig:thresholded_image2.5_2}
\end{figure}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_reconstructed_20.png}
    \caption{The reconstructed riverside image using the thresholded Daubechies wavelet transform coefficients, for a top 20\% threshold.}
    \label{fig:reconstructed_image20}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_diff_20.png}
    \caption{The difference between the original and reconstructed riverside images, for a top 20\% threshold.}
    \label{fig:diff_image20}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_reconstructed_10.png}
    \caption{The reconstructed riverside image using the thresholded Daubechies wavelet transform coefficients, for a top 10\% threshold.}
    \label{fig:reconstructed_image10}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_diff_10.png}
    \caption{The difference between the original and reconstructed riverside images, for a top 10\% threshold.}
    \label{fig:diff_image10}
\end{figure}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_reconstructed_5.png}
    \caption{The reconstructed riverside image using the thresholded Daubechies wavelet transform coefficients, for a top 5\% threshold.}
    \label{fig:reconstructed_image5}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_diff_5.png}
    \caption{The difference between the original and reconstructed riverside images, for a top 5\% threshold.}
    \label{fig:diff_image5}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_reconstructed_2_5.png}
    \caption{The reconstructed riverside image using the thresholded Daubechies wavelet transform coefficients, for a top 2.5\% threshold.}
    \label{fig:reconstructed_image2.5}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../Plots/q2.3_riverside_diff_2_5.png}
    \caption{The difference between the original and reconstructed riverside images, for a top 2.5\% threshold.}
    \label{fig:diff_image2.5}
\end{figure}



\bibliographystyle{plain}
\bibliography{refs.bib}

\end{document}
